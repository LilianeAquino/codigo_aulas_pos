{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseado no tutorial: https://keras.io/examples/nlp/text_classification_from_scratch/\n",
    "\n",
    "# importando bibliotecas basicas\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, class_label):\n",
    "\n",
    "    file_names = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_dir):\n",
    "        for f in filenames:\n",
    "            if f.endswith(\".txt\"):\n",
    "                file_names.append(os.path.join(dirpath, f))\n",
    "\n",
    "    txt_ = []\n",
    "    y = []\n",
    "    for f in file_names: \n",
    "        txt_.append(codecs.open(f,'r',encoding='iso8859-1').read())\n",
    "        y.append(class_label)\n",
    "\n",
    "    return txt_, y\n",
    "\n",
    "fake_data, y_fake = load_data('../aula05/Fake.Br Corpus/full_texts/fake/', 1)    \n",
    "true_data, y_true = load_data('../aula05/Fake.Br Corpus/full_texts/true/', 2)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, y_train, y_test = train_test_split(fake_data + true_data, y_fake + y_true,test_size=0.15, random_state=1447)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Juiz determina Ã¡rea para manifestantes e proÃ­be acampamento do MST durante julgamento de Lula em Porto Alegre\r\n",
      "\r\n",
      "Recurso do ex-presidente serÃ¡ julgado em segunda instÃ¢ncia em 24 de janeiro de 2018. Pedido do MPF para evitar protestos no dia foi atendido parcialmente pelo juiz.\r\n",
      "\r\n",
      "juiz federal OsÃ³rio Ãvila Neto determinou que seja estabelecida uma Ã¡rea onde os manifestantes deverÃ£o ficar nas imediaÃ§Ãµes do Tribunal Regional Federal da 4a RegiÃ£o, em Porto Alegre, no dia do julgamento do recurso do ex-presidente Luiz InÃ¡cio Lula da Silva em segunda instÃ¢ncia, em 24 de janeiro de 2018. O magistrado ainda citou que deverÃ¡ haver um isolamento para o trÃ¢nsito nas vias prÃ³ximas ao prÃ©dio.\r\n",
      "\r\n",
      "Em maio, durante o primeiro depoimento de Lula como rÃ©u em Curitiba, as autoridades do ParanÃ¡ montaram um esquema de seguranÃ§a em funÃ§Ã£o das manifestaÃ§Ãµes de apoiadores e grupos contrÃ¡rios ao ex-presidente.\r\n",
      "\r\n",
      "A aÃ§Ã£o civil pÃºblica foi protocolada pelo MinistÃ©rio PÃºblico Federal (MPF) e solicitava que o Parque MaurÃ­cio Sirotski Sobrinho, situado em frente ao TRF4, fosse interditado, para evitar protestos no local. O pedido foi atendido parcialmente pelo juiz.\r\n",
      "\r\n",
      "No despacho, publicado na quinta-feira (28) Ã  noite, Neto proibiu a instalaÃ§Ã£o de acampamento do Movimento de Trabalhadores Rurais Sem Terra (MST) na Ã¡rea do parque e nos terrenos vizinhos, atÃ© trÃªs dias apÃ³s o julgamento. Mas os manifestantes poderÃ£o acessar a Ã¡rea.\r\n",
      "\r\n",
      "\"Uma vez que a ocupaÃ§Ã£o do Parque da Harmonia por particulares necessita de prÃ©vio assentimento do Poder PÃºblico, mas nÃ£o a circulaÃ§Ã£o de pessoas por ali, e dado o carÃ¡ter auto-executivo que caracteriza o poder de polÃ­cia, defiro a proibiÃ§Ã£o de formaÃ§Ã£o de acampamento no interior do Parque MaurÃ­cio Sirotski Sobrinho, e em seus terrenos e estacionamentos lindeiros, cabendo ao Poder PÃºblico, mormente suas forÃ§as policiais, zelar pela cumprimento desta decisÃ£o\", escreveu.\r\n",
      "\r\n",
      "No texto, o juiz defendeu o direito Ã s manifestaÃ§Ãµes, mas repetiu que os atos devem ser previamente informados. \"O direito de manifestaÃ§Ã£o estÃ¡ garantido constitucionalmente, para tanto basta que seja previamente informado o local de reuniÃ£o Ã s autoridades e se desenvolva de modo ordeiro\", sustentou o juiz.\r\n",
      "\r\n",
      "O MPF tambÃ©m solicitava que o Parque da RedenÃ§Ã£o fosse designado para receber protestos a favor de Lula, e o Parque Moinhos de Vento recebesse apenas manifestantes contrÃ¡rios ao petista, mas o pedido foi negado pelo juiz federal.\r\n",
      "\r\n",
      "A decisÃ£o provocou reaÃ§Ãµes do Partido dos Trabalhadores e do MST. Em 15 de dezembro, o movimento no Rio Grande do Sul definiu que montaria um acampamento na capital gaÃºcha no mÃªs de janeiro, devido ao julgamento de Lula.\r\n",
      "\r\n",
      "Em nota, a ComissÃ£o Executiva Nacional do PT afirmou que a decisÃ£o Ã© um \"ataque Ã  democracia\", que os atos a favor de Lula sempre foram pacÃ­ficos e legÃ­timos, e que utilizarÃ¡ \"todas as medidas judiciais cabÃ­veis\".\r\n",
      "\r\n",
      "MST diz que vai manter mobilizaÃ§Ã£o\r\n",
      "Por meio de nota, o MST informou que continuarÃ¡ com a mobilizaÃ§Ã£o marcada para a semana em que acontece o julgamento do recurso, e que nÃ£o deve recorrer da decisÃ£o.\r\n",
      "\r\n",
      "\"O Movimento nÃ£o vai recorrer da decisÃ£o do juiz OsÃ³rio Avila Neto, que proibiu a instalaÃ§Ã£o de acampamento de Trabalhadores Rurais Sem Terra e a realizaÃ§Ã£o de manifestaÃ§Ãµes nas proximidades do prÃ©dio do Tribunal na capital gaÃºcha, mas reafirma a importÃ¢ncia da unidade de trabalhadores e trabalhadoras e a legitimidade de promover suas livres manifestaÃ§Ãµes de apoio polÃ­tico junto com outros movimentos populares, centrais sindicais e militantes de partidos polÃ­ticos\", diz o comunicado.\r\n",
      "\r\n",
      "Julgamento de Lula\r\n",
      "O julgamento do recurso apresentado pelo ex-presidente Luiz InÃ¡cio Lula da Silva no processo do triplex em GuarujÃ¡ serÃ¡ realizado Ã s 8h30 do dia 24 de janeiro de 2018, na sede do Tribunal Regional da 4a RegiÃ£o (TRF4), em Porto Alegre.\r\n",
      "\r\n",
      "A data foi marcada em 12 de dezembro pela 8a Turma da Corte. Em nota, a defesa de Lula criticou a \"tramitaÃ§Ã£o recorde\" do processo.\r\n",
      "\r\n",
      "Em julho, Lula foi condenado pelo juiz Sergio Moro, responsÃ¡vel pela Lava Jato na primeira instÃ¢ncia, a 9 anos e seis meses de prisÃ£o por corrupÃ§Ã£o passiva e lavagem de dinheiro no processo envolvendo o triplex. A acusaÃ§Ã£o foi de ocultaÃ§Ã£o da propriedade do imÃ³vel, recebido como propina da empreiteira OAS em troca de favores na Petrobras.\r\n",
      "\r\n",
      "Outros dois rÃ©us no mesmo processo tambÃ©m foram condenados, e quatro, absolvidos.\r\n",
      "\r\n",
      "A JustiÃ§a Federal no ParanÃ¡ tambÃ©m determinou o bloqueio de R$ 16 milhÃµes, estabelecido como dano mÃ­nimo, e o sequestro do apartamento. Lula tambÃ©m teve bloqueados mais de R$ 600 mil de contas bancÃ¡rias e cerca de R$ 9 milhÃµes que estavam depositados em dois planos de previdÃªncia privada.\r\n",
      "\r\n",
      "A sentenÃ§a publicada no dia 12 de julho permite que o petista recorra em liberdade.\r\n",
      "\r\n",
      "De acordo com a assessoria do TRF4, a marcaÃ§Ã£o do julgamento ocorreu pela necessidade de prazo hÃ¡bil mÃ­nimo para intimaÃ§Ã£o das partes e por conta do recesso do tribunal, que serÃ¡ de 20 de dezembro a 6 de janeiro.\r\n",
      "\r\n",
      "No dia 15 de dezembro, o TRF4 publicou um despacho do presidente da corte Carlos Eduardo Thompson Flores Lenz com informaÃ§Ãµes sobre os processos julgados neste ano, atÃ© o dia 13. Segundo o documento, mais de 49% dos casos foram concluÃ­dos em menos de 150 dias â no caso do ex-presidente, a demora serÃ¡ de 127 dias.\r\n",
      "\r\n",
      "Caso os desembargadores decidam manter a decisÃ£o da primeira instÃ¢ncia, eles podem determinar a prisÃ£o de Lula â que, no caso, seria executada por Moro em Curitiba â ou decidir que o ex-presidente sÃ³ irÃ¡ para a prisÃ£o apÃ³s todos os recursos terem sido esgotados.\r\n",
      "\r\n",
      "Em 2016, o Supremo Tribunal Federal (STF) determinou que um rÃ©u condenado em segunda instÃ¢ncia jÃ¡ comece a cumprir a pena de prisÃ£o mesmo que esteja recorrendo aos tribunais superiores. O assunto, porÃ©m, deve voltar a ser discutido pelos ministros, mas ainda nÃ£o hÃ¡ data para esse julgamento.\r\n",
      "\r\n",
      "A inelegibilidade de Lula, por sua vez, Ã© assunto para a JustiÃ§a Eleitoral. A Lei da Ficha Limpa prevÃª que um condenado em segunda instÃ¢ncia â como seria o caso do ex-presidente, caso os desembargadores confirmem a sentenÃ§a â nÃ£o pode se candidatar.\r\n",
      "\r\n",
      "Mas uma eventual condenaÃ§Ã£o, por si sÃ³, nÃ£o influenciaria em uma possÃ­vel candidatura. Neste caso, a decisÃ£o ficaria por conta do Tribunal Superior Eleitoral (TSE), que pode ser acionado pelo MinistÃ©rio PÃºblico Eleitoral (MPE) ou por algum adversÃ¡rio polÃ­tico, ou ainda decidir por iniciativa prÃ³pria do magistrado.\r\n",
      "\r\n",
      "Ainda assim, Lula teria duas possibilidades de recurso: ao pleno do TSE e ao Supremo Tribunal Federal (STF).\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# É importante dar uma olhada no seu dado original para garantir a sua normalização\n",
    "# e tokenização estejam da forma como você espera. Nós podemos fazer isso pegando \n",
    "# alguns poucos exemplos do conjunto de treino e olhando eles.\n",
    "print(data_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas necessarias para o pre-processamento de dados\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padronizando os nossos dados com o que ja conhecemos: \n",
    "# colocando com letra minúscula e removendo pontuacao\n",
    "def padronizacao_customizada(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Constantes do modelo\n",
    "# as nossas features serao nossas palavras, no nosso modelo teremos no maximo 20000 palavras\n",
    "max_features = 20000 \n",
    "# aqui a nossa camada de embedding sera embutida, portanto o treinamento dos vetores embeddings acontecerá \n",
    "# logo antes de passar pela nossa CNN\n",
    "embedding_dim = 128 \n",
    "# tamanho fixo que um texto do nosso dataset pode ter, você pode limitar em qualquer tamanho, mas lembre-se \n",
    "# que quanto maior, mais memoria será necessaria\n",
    "sequence_length = 500\n",
    "\n",
    "# agora que temos nossa padronização customizada, podemos instanciar o nosso texto\n",
    "# na camada de vetorização. Nós estamos usando esta camada para normalizar, dividir e mapear\n",
    "# string para inteiros, assim nós setamos nosso 'output_mode' para 'int'\n",
    "# Note que nós estamos usando uma função para dividir \"padrão\", e \n",
    "# a normalização definida acima.\n",
    "# Nós também setamos um tamanho máximo para o nosso texto (sequence_length), visto que\n",
    "# CNNs em nosso modelo não suportam sequências de tamanhos diferentes.\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=padronizacao_customizada,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "# agora que a camada de vocabulario foi criada, chame 'adapt' em um dataset\n",
    "# só de texto para criar o vocabulário. Não precisar ser em \"lote\", mas para pequenos \n",
    "# datasets isso significa que você não está mantendo cópias sobressalentes do \n",
    "# dataset na memória\n",
    "\n",
    "# Agora vamos chamar `adapt` para criar o nosso vocabulário:\n",
    "vectorize_layer.adapt(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vetorizando o texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformacao dos textos em indices de números inteiros\n",
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label\n",
    "\n",
    "\n",
    "# Vetorização dos dados the data.\n",
    "train_ds,y_train = vectorize_text(data_train, y_train)\n",
    "test_ds, y_test = vectorize_text(data_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo um modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqui vamos usar uma camada de convolução + pooling com uma camada de embedding\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Uma entrada inteira para os indices do vocabulario\n",
    "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# A seguir, adicionams uma camada para mapear estes indices em um espaço \n",
    "# de dimensionalidade 'embedding_dim'\n",
    "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# Por fim adicionamos no final uma cama escondida básica:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# E projetammos em uma única unidade de saida \n",
    "# para \"compactar\" com uma sigmoid\n",
    "predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 128)         114816    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,806,273\n",
      "Trainable params: 2,806,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamos o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "192/192 [==============================] - 23s 117ms/step - loss: -793542131712.0000 - accuracy: 0.4993\n",
      "Epoch 2/3\n",
      "192/192 [==============================] - 24s 123ms/step - loss: -1297875992576.0000 - accuracy: 0.4993\n",
      "Epoch 3/3\n",
      "192/192 [==============================] - 29s 149ms/step - loss: -2010227146752.0000 - accuracy: 0.4993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd046b22fd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "# Fit the model using the train and test datasets.\n",
    "model.fit(train_ds, np.array(y_train), batch_size=32, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliamos o modelo no nosso conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 20ms/step - loss: -584878325760.0000 - accuracy: 0.5037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-584878325760.0, 0.5037037134170532]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds, np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
